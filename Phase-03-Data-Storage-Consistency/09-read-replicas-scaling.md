# Read Replicas & Scaling Reads: Handling High Read Traffic

## 0ï¸âƒ£ Prerequisites

Before diving into read replicas and scaling reads, you should understand:

- **Database Replication**: How data is copied from primary to replicas (covered in Topic 4).
- **Consistency Models**: Strong vs eventual consistency and their trade-offs (covered in Topic 6).
- **Connection Pooling Basics**: Reusing database connections instead of creating new ones for each request.

**Quick refresher on the read scaling problem**: A single database server can handle perhaps 10,000-50,000 queries per second. If your application needs 500,000 queries per second, you need multiple servers. Since writes must go to one place (the primary), you scale reads by adding replicas.

---

## 1ï¸âƒ£ What Problem Does This Exist to Solve?

### The Specific Pain Point

Imagine you're running a popular news website:

```
Traffic pattern:
- 100,000 users reading articles simultaneously
- Each page load = 5 database queries
- Total: 500,000 queries per second

Database capacity:
- Single PostgreSQL server: ~20,000 queries/second
- Result: 25x overloaded!
```

**What happens when overloaded**:
- Query queue grows
- Response times increase (100ms â†’ 5 seconds)
- Connections exhausted
- Timeouts and errors
- Users leave

### The Read vs Write Asymmetry

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TYPICAL READ/WRITE RATIO                        â”‚
â”‚                                                              â”‚
â”‚  E-commerce product pages:  99% reads, 1% writes            â”‚
â”‚  Social media feeds:        95% reads, 5% writes            â”‚
â”‚  Banking dashboards:        90% reads, 10% writes           â”‚
â”‚  Logging systems:           10% reads, 90% writes           â”‚
â”‚                                                              â”‚
â”‚  Most applications are READ-HEAVY                           â”‚
â”‚                                                              â”‚
â”‚  Key insight:                                                â”‚
â”‚  - Writes MUST go to primary (for consistency)              â”‚
â”‚  - Reads CAN go to replicas (if staleness acceptable)       â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What Breaks Without Read Scaling

**1. Connection Exhaustion**

```
PostgreSQL default: max_connections = 100
Each web server: 20 connections
5 web servers: 100 connections

Add 6th web server: No connections available!
New requests fail with "too many connections"
```

**2. Query Queuing**

```
Database can process: 1000 queries/second
Incoming: 5000 queries/second

Query queue grows by 4000/second
After 10 seconds: 40,000 queries waiting
Average wait time: 40 seconds
Users see timeouts
```

**3. Resource Contention**

```
Single server handling everything:
- CPU: 100% (query processing)
- Memory: Full (caching, sorting)
- Disk I/O: Saturated (reads + writes)
- Network: Bottleneck

Everything competes for same resources
Performance degrades for everyone
```

### Real Examples

**Stack Overflow**: Uses read replicas for their high-traffic Q&A pages. Primary handles writes (new questions, answers), replicas handle the massive read traffic.

**GitHub**: Read replicas serve repository browsing. Primary handles pushes and writes.

**Shopify**: Product catalog reads go to replicas. Order writes go to primary.

---

## 2ï¸âƒ£ Intuition and Mental Model

### The Library Analogy (Extended)

**Single Database = One Librarian**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   ONE LIBRARIAN                              â”‚
â”‚                                                              â”‚
â”‚  100 people asking questions simultaneously                 â”‚
â”‚                                                              â”‚
â”‚  Person 1: "Where is book X?" (read)                        â”‚
â”‚  Person 2: "Where is book Y?" (read)                        â”‚
â”‚  Person 3: "Add this new book" (write)                      â”‚
â”‚  Person 4: "Where is book Z?" (read)                        â”‚
â”‚  ...                                                         â”‚
â”‚  Person 100: Still waiting...                               â”‚
â”‚                                                              â”‚
â”‚  One librarian can only help one person at a time          â”‚
â”‚  Long queues form                                           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Read Replicas = Multiple Librarians with Copies**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            MULTIPLE LIBRARIANS (Read Replicas)               â”‚
â”‚                                                              â”‚
â”‚  HEAD LIBRARIAN (Primary):                                  â”‚
â”‚  - Only one who can add/modify books                        â”‚
â”‚  - Keeps the master catalog                                 â”‚
â”‚  - Sends updates to assistants                              â”‚
â”‚                                                              â”‚
â”‚  ASSISTANT LIBRARIANS (Replicas):                           â”‚
â”‚  - Have copies of the catalog                               â”‚
â”‚  - Can answer "where is book X?" questions                  â”‚
â”‚  - Cannot add or modify books                               â”‚
â”‚                                                              â”‚
â”‚  Traffic distribution:                                       â”‚
â”‚  - "Add new book" â†’ Head librarian only                     â”‚
â”‚  - "Where is book?" â†’ Any assistant (load balanced)         â”‚
â”‚                                                              â”‚
â”‚  Result: 5 assistants = 5x read capacity!                   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Connection Pooling = Shared Phone Lines

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CONNECTION POOLING ANALOGY                      â”‚
â”‚                                                              â”‚
â”‚  WITHOUT POOLING:                                           â”‚
â”‚  Each call = New phone line installed                       â”‚
â”‚  Call ends = Phone line removed                             â”‚
â”‚  Next call = Install new line again                         â”‚
â”‚  Cost: High (installation time for each call)               â”‚
â”‚                                                              â”‚
â”‚  WITH POOLING:                                              â”‚
â”‚  Office has 20 shared phone lines                           â”‚
â”‚  Call comes in = Use available line                         â”‚
â”‚  Call ends = Line returned to pool                          â”‚
â”‚  Next call = Reuse existing line                            â”‚
â”‚  Cost: Low (lines already installed)                        â”‚
â”‚                                                              â”‚
â”‚  Database connections are expensive to create:              â”‚
â”‚  - TCP handshake                                            â”‚
â”‚  - Authentication                                           â”‚
â”‚  - Session setup                                            â”‚
â”‚  - Memory allocation                                        â”‚
â”‚                                                              â”‚
â”‚  Pooling reuses connections = much faster!                  â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3ï¸âƒ£ How It Works Internally

### Read Replica Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              READ REPLICA ARCHITECTURE                       â”‚
â”‚                                                              â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                    â”‚   APPLICATION   â”‚                      â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚                             â”‚                                â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚              â”‚                              â”‚                â”‚
â”‚              â–¼                              â–¼                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚   WRITE PATH        â”‚      â”‚   READ PATH          â”‚      â”‚
â”‚  â”‚                     â”‚      â”‚                      â”‚      â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚      â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚
â”‚  â”‚   â”‚   Primary   â”‚   â”‚      â”‚   â”‚Load Balancer â”‚  â”‚      â”‚
â”‚  â”‚   â”‚  (writes)   â”‚â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â–¶â”‚              â”‚  â”‚      â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â”‚      â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚      â”‚
â”‚  â”‚          â”‚          â”‚      â”‚          â”‚          â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”  â”‚      â”‚
â”‚             â”‚ Replication     â”‚   â”‚              â”‚  â”‚      â”‚
â”‚             â”‚                 â”‚   â–¼              â–¼  â”‚      â”‚
â”‚             â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚      â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Replica 1â”‚    â”‚ Replica 2â”‚â”‚      â”‚
â”‚             â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚      â”‚
â”‚             â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚      â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚ Replica 3â”‚    â”‚ Replica 4â”‚â”‚      â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚      â”‚
â”‚                                                     â”‚      â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Replication Lag

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REPLICATION LAG                           â”‚
â”‚                                                              â”‚
â”‚  Timeline:                                                   â”‚
â”‚                                                              â”‚
â”‚  T=0ms:    Write to Primary: user.name = "Alice"            â”‚
â”‚  T=1ms:    Primary acknowledges write                       â”‚
â”‚  T=5ms:    Primary sends WAL to Replica 1                   â”‚
â”‚  T=10ms:   Replica 1 applies change                         â”‚
â”‚  T=15ms:   Primary sends WAL to Replica 2                   â”‚
â”‚  T=50ms:   Replica 2 applies change (slower network)        â”‚
â”‚                                                              â”‚
â”‚  Replication lag:                                            â”‚
â”‚  - Replica 1: 10ms                                          â”‚
â”‚  - Replica 2: 50ms                                          â”‚
â”‚                                                              â”‚
â”‚  If user reads from Replica 2 at T=20ms:                    â”‚
â”‚  â†’ Sees OLD value (stale read)                              â”‚
â”‚                                                              â”‚
â”‚  Causes of lag:                                              â”‚
â”‚  - Network latency                                          â”‚
â”‚  - Replica under load                                       â”‚
â”‚  - Large transactions                                       â”‚
â”‚  - Disk I/O on replica                                      â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Connection Pooling Internals

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CONNECTION POOL INTERNALS                       â”‚
â”‚                                                              â”‚
â”‚  Pool Configuration:                                         â”‚
â”‚  - Minimum connections: 5 (always ready)                    â”‚
â”‚  - Maximum connections: 20 (cap)                            â”‚
â”‚  - Idle timeout: 10 minutes                                 â”‚
â”‚  - Connection lifetime: 30 minutes                          â”‚
â”‚                                                              â”‚
â”‚  Pool State:                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Active: [Conn1, Conn2, Conn3]  (in use)             â”‚   â”‚
â”‚  â”‚ Idle:   [Conn4, Conn5, Conn6, Conn7]  (available)   â”‚   â”‚
â”‚  â”‚ Pending: 2 requests waiting                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  Request flow:                                               â”‚
â”‚  1. Request arrives                                         â”‚
â”‚  2. Check idle pool                                         â”‚
â”‚     - If available: Return connection                       â”‚
â”‚     - If empty and < max: Create new connection            â”‚
â”‚     - If at max: Wait in queue (with timeout)              â”‚
â”‚  3. Execute query                                           â”‚
â”‚  4. Return connection to idle pool                          â”‚
â”‚                                                              â”‚
â”‚  Connection lifecycle:                                       â”‚
â”‚  - Created: TCP + Auth + Session setup (~50-100ms)         â”‚
â”‚  - Reused: Just execute query (~1ms overhead)              â”‚
â”‚  - Closed: After idle timeout or lifetime exceeded         â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Read-After-Write Consistency Problem

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           READ-AFTER-WRITE PROBLEM                           â”‚
â”‚                                                              â”‚
â”‚  User Action Flow:                                           â”‚
â”‚                                                              â”‚
â”‚  1. User updates profile name to "Alice Smith"              â”‚
â”‚     â†’ Write goes to Primary                                 â”‚
â”‚     â†’ Primary returns "Success"                             â”‚
â”‚                                                              â”‚
â”‚  2. User views their profile                                â”‚
â”‚     â†’ Read goes to Replica (load balanced)                  â”‚
â”‚     â†’ Replica hasn't received update yet                    â”‚
â”‚     â†’ User sees old name "Alice Jones"                      â”‚
â”‚                                                              â”‚
â”‚  User reaction: "Where's my update?!" ğŸ˜¡                    â”‚
â”‚                                                              â”‚
â”‚  Solutions:                                                  â”‚
â”‚                                                              â”‚
â”‚  A. Read from Primary after write                           â”‚
â”‚     - For N seconds after write, read from Primary          â”‚
â”‚     - Simple but increases Primary load                     â”‚
â”‚                                                              â”‚
â”‚  B. Version tracking                                         â”‚
â”‚     - Track user's last write version                       â”‚
â”‚     - Read from replica only if version >= last write       â”‚
â”‚     - More complex but scales better                        â”‚
â”‚                                                              â”‚
â”‚  C. Sticky sessions                                          â”‚
â”‚     - Route user to same replica                            â”‚
â”‚     - Replica that received replication first               â”‚
â”‚     - Limits load balancing flexibility                     â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Stale Read Handling

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              STALE READ HANDLING STRATEGIES                  â”‚
â”‚                                                              â”‚
â”‚  Strategy 1: Accept Staleness                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ For non-critical reads (analytics, dashboards)       â”‚   â”‚
â”‚  â”‚ Just read from any replica                           â”‚   â”‚
â”‚  â”‚ Staleness of seconds is acceptable                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  Strategy 2: Bounded Staleness                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Check replica lag before reading                     â”‚   â”‚
â”‚  â”‚ If lag > threshold, route to Primary                 â”‚   â”‚
â”‚  â”‚ Guarantees max staleness                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  Strategy 3: Causal Consistency                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Track dependencies between operations                â”‚   â”‚
â”‚  â”‚ Ensure reads see causally related writes             â”‚   â”‚
â”‚  â”‚ More complex but stronger guarantees                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  Strategy 4: Synchronous Replication                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Wait for replica to confirm before ack write         â”‚   â”‚
â”‚  â”‚ Zero lag but slower writes                           â”‚   â”‚
â”‚  â”‚ Use for critical data only                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4ï¸âƒ£ Simulation-First Explanation

### Scenario 1: Read Scaling in Action

```
Setup:
- 1 Primary (writes + some reads)
- 4 Read Replicas
- Load balancer distributing reads

Traffic: 100,000 read queries/second

Without replicas:
  Primary capacity: 20,000 qps
  Incoming: 100,000 qps
  Result: 80,000 queries queued, massive latency

With 4 replicas:
  Total read capacity: 4 Ã— 20,000 = 80,000 qps
  Primary handles: 20,000 qps
  Total: 100,000 qps âœ“
  
  Distribution:
  - Replica 1: 25,000 qps
  - Replica 2: 25,000 qps
  - Replica 3: 25,000 qps
  - Replica 4: 25,000 qps
  
  Each replica at ~125% capacity (needs 5th replica!)
```

### Scenario 2: Connection Pool Behavior

```
Setup:
- Pool: min=5, max=20, timeout=30s
- Database query time: 10ms average

Steady state (low traffic):
  T=0:    Pool: 5 idle connections
  T=1ms:  Request 1 arrives, gets Conn1
  T=5ms:  Request 2 arrives, gets Conn2
  T=11ms: Request 1 completes, Conn1 returned to pool
  T=15ms: Request 3 arrives, gets Conn1 (reused!)

Traffic spike:
  T=0:    Pool: 5 idle, 0 active
  T=1ms:  20 requests arrive simultaneously
  
  T=1ms:  5 requests get existing connections
  T=2ms:  5 more connections created (now at 10)
  T=3ms:  5 more connections created (now at 15)
  T=4ms:  5 more connections created (now at 20, max!)
  T=5ms:  Remaining 5 requests WAIT in queue
  
  T=11ms: First 5 requests complete, return connections
  T=12ms: Waiting requests get connections
  
Total time for all 20 requests: ~22ms
Without pooling: 20 Ã— 100ms (connection setup) = 2000ms!
```

### Scenario 3: Handling Replication Lag

```
Setup:
- Primary in US-East
- Replica in US-West (50ms network latency)
- Async replication

User updates profile:
  T=0ms:    User submits: name = "Alice Smith"
  T=1ms:    Write to Primary succeeds
  T=2ms:    Response to user: "Profile updated!"
  
  T=10ms:   Primary sends WAL to Replica
  T=60ms:   Replica receives WAL
  T=65ms:   Replica applies change

User views profile at T=30ms:
  Request routed to Replica (closer to user)
  Replica still has old data!
  User sees: "Alice Jones" (old name)
  
  User: "But I just updated it!" ğŸ˜¤

Solution with version tracking:
  T=2ms:    Response includes: version=42
  T=30ms:   User request includes: min_version=42
  T=30ms:   Replica version=41 < 42
            â†’ Route to Primary instead
  T=35ms:   User sees: "Alice Smith" âœ“
```

---

## 5ï¸âƒ£ How Engineers Actually Use This in Production

### At Major Companies

**Instagram**:
- PostgreSQL with many read replicas
- Memcached in front for hot data
- Read replicas for user feeds, profiles
- Primary for posts, follows, likes

**Netflix**:
- Cassandra with local replicas per region
- EVCache (Memcached) for session data
- Read from local datacenter for low latency

**Uber**:
- MySQL with read replicas per city
- Schemaless (custom) for high-write data
- Redis for real-time data

### Connection Pooling Best Practices

**HikariCP Configuration (Java)**:

```yaml
# application.yml
spring:
  datasource:
    hikari:
      # Pool sizing
      minimum-idle: 5           # Min connections to keep
      maximum-pool-size: 20     # Max connections
      
      # Timeouts
      connection-timeout: 30000  # 30s to get connection
      idle-timeout: 600000       # 10min idle before close
      max-lifetime: 1800000      # 30min max connection life
      
      # Leak detection
      leak-detection-threshold: 60000  # Warn if held > 60s
      
      # Validation
      connection-test-query: SELECT 1
      validation-timeout: 5000   # 5s to validate
```

**PgBouncer Configuration (PostgreSQL)**:

```ini
[databases]
mydb = host=primary.db.local port=5432 dbname=mydb

[pgbouncer]
# Pool mode
pool_mode = transaction  # Return to pool after transaction

# Pool sizing
default_pool_size = 20   # Connections per user/database
max_client_conn = 1000   # Total client connections
reserve_pool_size = 5    # Extra connections for spikes

# Timeouts
server_idle_timeout = 600   # Close idle server connections
client_idle_timeout = 0     # Don't close idle clients
query_timeout = 0           # No query timeout
```

### Monitoring Replication Lag

```sql
-- PostgreSQL: Check replication lag on Primary
SELECT 
    client_addr,
    state,
    sent_lsn,
    write_lsn,
    flush_lsn,
    replay_lsn,
    pg_wal_lsn_diff(sent_lsn, replay_lsn) AS lag_bytes,
    pg_wal_lsn_diff(sent_lsn, replay_lsn) / 1024 / 1024 AS lag_mb
FROM pg_stat_replication;

-- PostgreSQL: Check lag on Replica (seconds)
SELECT 
    CASE 
        WHEN pg_last_wal_receive_lsn() = pg_last_wal_replay_lsn() 
        THEN 0 
        ELSE EXTRACT(EPOCH FROM now() - pg_last_xact_replay_timestamp())
    END AS replication_lag_seconds;

-- MySQL: Check replica status
SHOW SLAVE STATUS\G
-- Look for: Seconds_Behind_Master
```

---

## 6ï¸âƒ£ How to Implement or Apply It

### Spring Boot Read/Write Splitting

```java
package com.example.readreplica.config;

import com.zaxxer.hikari.HikariDataSource;
import org.springframework.jdbc.datasource.lookup.AbstractRoutingDataSource;
import org.springframework.transaction.support.TransactionSynchronizationManager;
import javax.sql.DataSource;
import java.util.HashMap;
import java.util.Map;

/**
 * Routes queries to primary or replica based on transaction type.
 */
public class ReadWriteRoutingDataSource extends AbstractRoutingDataSource {
    
    @Override
    protected Object determineCurrentLookupKey() {
        // Read-only transactions go to replica
        if (TransactionSynchronizationManager.isCurrentTransactionReadOnly()) {
            return "replica";
        }
        return "primary";
    }
}

@Configuration
public class DataSourceConfig {
    
    @Bean
    @ConfigurationProperties("spring.datasource.primary")
    public DataSource primaryDataSource() {
        return new HikariDataSource();
    }
    
    @Bean
    @ConfigurationProperties("spring.datasource.replica")
    public DataSource replicaDataSource() {
        return new HikariDataSource();
    }
    
    @Bean
    @Primary
    public DataSource routingDataSource() {
        ReadWriteRoutingDataSource routingDataSource = new ReadWriteRoutingDataSource();
        
        Map<Object, Object> dataSources = new HashMap<>();
        dataSources.put("primary", primaryDataSource());
        dataSources.put("replica", replicaDataSource());
        
        routingDataSource.setTargetDataSources(dataSources);
        routingDataSource.setDefaultTargetDataSource(primaryDataSource());
        
        return routingDataSource;
    }
}
```

**Application Configuration**:

```yaml
# application.yml
spring:
  datasource:
    primary:
      jdbc-url: jdbc:postgresql://primary.db.local:5432/mydb
      username: app_user
      password: ${DB_PASSWORD}
      hikari:
        maximum-pool-size: 10
        pool-name: primary-pool
    
    replica:
      jdbc-url: jdbc:postgresql://replica.db.local:5432/mydb
      username: app_user
      password: ${DB_PASSWORD}
      hikari:
        maximum-pool-size: 30  # More connections for reads
        pool-name: replica-pool
```

**Service Usage**:

```java
package com.example.readreplica.service;

import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Transactional;

@Service
public class UserService {
    
    private final UserRepository userRepository;
    
    public UserService(UserRepository userRepository) {
        this.userRepository = userRepository;
    }
    
    /**
     * Read-only transaction â†’ Routes to replica
     */
    @Transactional(readOnly = true)
    public User findById(Long id) {
        return userRepository.findById(id).orElseThrow();
    }
    
    /**
     * Read-only transaction â†’ Routes to replica
     */
    @Transactional(readOnly = true)
    public List<User> findByCountry(String country) {
        return userRepository.findByCountry(country);
    }
    
    /**
     * Write transaction â†’ Routes to primary
     */
    @Transactional
    public User createUser(UserRequest request) {
        User user = new User(request.getName(), request.getEmail());
        return userRepository.save(user);
    }
    
    /**
     * Write transaction â†’ Routes to primary
     */
    @Transactional
    public User updateUser(Long id, UserRequest request) {
        User user = userRepository.findById(id).orElseThrow();
        user.setName(request.getName());
        user.setEmail(request.getEmail());
        return userRepository.save(user);
    }
}
```

### Read-Your-Writes Implementation

```java
package com.example.readreplica.consistency;

import org.springframework.stereotype.Component;
import org.springframework.web.context.request.RequestContextHolder;
import org.springframework.web.context.request.ServletRequestAttributes;
import jakarta.servlet.http.HttpSession;
import java.time.Instant;
import java.util.Map;
import java.util.concurrent.ConcurrentHashMap;

/**
 * Tracks user's last write to ensure read-your-writes consistency.
 */
@Component
public class WriteVersionTracker {
    
    // In production, use Redis for distributed tracking
    private final Map<String, Map<String, Instant>> userWriteTimestamps = 
        new ConcurrentHashMap<>();
    
    /**
     * Record that a user wrote to a specific entity.
     */
    public void recordWrite(String userId, String entityType, String entityId) {
        String key = entityType + ":" + entityId;
        userWriteTimestamps
            .computeIfAbsent(userId, k -> new ConcurrentHashMap<>())
            .put(key, Instant.now());
    }
    
    /**
     * Check if user recently wrote to this entity.
     * If so, should read from primary.
     */
    public boolean shouldReadFromPrimary(String userId, String entityType, 
                                          String entityId, int maxStalenessSeconds) {
        String key = entityType + ":" + entityId;
        Map<String, Instant> userWrites = userWriteTimestamps.get(userId);
        
        if (userWrites == null) {
            return false;  // User hasn't written, replica is fine
        }
        
        Instant lastWrite = userWrites.get(key);
        if (lastWrite == null) {
            return false;  // User hasn't written to this entity
        }
        
        // If write was recent, read from primary
        return lastWrite.plusSeconds(maxStalenessSeconds).isAfter(Instant.now());
    }
    
    /**
     * Clean up old entries (call periodically).
     */
    public void cleanupOldEntries(int maxAgeSeconds) {
        Instant cutoff = Instant.now().minusSeconds(maxAgeSeconds);
        
        userWriteTimestamps.forEach((userId, writes) -> {
            writes.entrySet().removeIf(entry -> entry.getValue().isBefore(cutoff));
        });
        
        userWriteTimestamps.entrySet().removeIf(entry -> entry.getValue().isEmpty());
    }
}
```

### Replication Lag Monitoring

```java
package com.example.readreplica.monitoring;

import io.micrometer.core.instrument.Gauge;
import io.micrometer.core.instrument.MeterRegistry;
import org.springframework.jdbc.core.JdbcTemplate;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

@Component
public class ReplicationLagMonitor {
    
    private final JdbcTemplate replicaJdbcTemplate;
    private final MeterRegistry meterRegistry;
    private volatile double lagSeconds = 0;
    
    public ReplicationLagMonitor(JdbcTemplate replicaJdbcTemplate,
                                  MeterRegistry meterRegistry) {
        this.replicaJdbcTemplate = replicaJdbcTemplate;
        this.meterRegistry = meterRegistry;
        
        Gauge.builder("db.replication.lag.seconds", () -> lagSeconds)
            .description("Replication lag in seconds")
            .tag("replica", "replica-1")
            .register(meterRegistry);
    }
    
    @Scheduled(fixedRate = 5000)  // Check every 5 seconds
    public void checkReplicationLag() {
        try {
            String sql = """
                SELECT CASE 
                    WHEN pg_last_wal_receive_lsn() = pg_last_wal_replay_lsn() THEN 0 
                    ELSE EXTRACT(EPOCH FROM now() - pg_last_xact_replay_timestamp())
                END AS lag_seconds
                """;
            
            Double lag = replicaJdbcTemplate.queryForObject(sql, Double.class);
            this.lagSeconds = lag != null ? lag : 0;
            
            // Alert if lag is too high
            if (lagSeconds > 30) {
                alertService.sendAlert("High replication lag: " + lagSeconds + "s");
            }
            
        } catch (Exception e) {
            log.error("Failed to check replication lag", e);
            this.lagSeconds = -1;  // Indicate error
        }
    }
    
    public double getLagSeconds() {
        return lagSeconds;
    }
    
    public boolean isReplicaHealthy(double maxAcceptableLag) {
        return lagSeconds >= 0 && lagSeconds <= maxAcceptableLag;
    }
}
```

### Connection Pool Monitoring

```java
package com.example.readreplica.monitoring;

import com.zaxxer.hikari.HikariDataSource;
import com.zaxxer.hikari.HikariPoolMXBean;
import io.micrometer.core.instrument.MeterRegistry;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Component;

@Component
public class ConnectionPoolMonitor {
    
    private final HikariDataSource primaryDataSource;
    private final HikariDataSource replicaDataSource;
    private final MeterRegistry meterRegistry;
    
    public ConnectionPoolMonitor(HikariDataSource primaryDataSource,
                                  HikariDataSource replicaDataSource,
                                  MeterRegistry meterRegistry) {
        this.primaryDataSource = primaryDataSource;
        this.replicaDataSource = replicaDataSource;
        this.meterRegistry = meterRegistry;
        
        registerPoolMetrics("primary", primaryDataSource);
        registerPoolMetrics("replica", replicaDataSource);
    }
    
    private void registerPoolMetrics(String name, HikariDataSource dataSource) {
        HikariPoolMXBean pool = dataSource.getHikariPoolMXBean();
        
        Gauge.builder("hikari.connections.active", pool::getActiveConnections)
            .tag("pool", name)
            .register(meterRegistry);
        
        Gauge.builder("hikari.connections.idle", pool::getIdleConnections)
            .tag("pool", name)
            .register(meterRegistry);
        
        Gauge.builder("hikari.connections.pending", pool::getThreadsAwaitingConnection)
            .tag("pool", name)
            .register(meterRegistry);
        
        Gauge.builder("hikari.connections.total", pool::getTotalConnections)
            .tag("pool", name)
            .register(meterRegistry);
    }
    
    @Scheduled(fixedRate = 10000)
    public void logPoolStats() {
        logPoolStatus("primary", primaryDataSource);
        logPoolStatus("replica", replicaDataSource);
    }
    
    private void logPoolStatus(String name, HikariDataSource ds) {
        HikariPoolMXBean pool = ds.getHikariPoolMXBean();
        
        log.info("Pool {}: active={}, idle={}, pending={}, total={}",
            name,
            pool.getActiveConnections(),
            pool.getIdleConnections(),
            pool.getThreadsAwaitingConnection(),
            pool.getTotalConnections());
        
        // Alert if pending connections > 0 for too long
        if (pool.getThreadsAwaitingConnection() > 0) {
            log.warn("Connections waiting in pool {}", name);
        }
    }
}
```

---

## 7ï¸âƒ£ Tradeoffs, Pitfalls, and Common Mistakes

### Common Mistake 1: Not Using Read Replicas for Reads

```java
// WRONG: All queries go to primary
@Transactional  // Default: not read-only
public User findById(Long id) {
    return userRepository.findById(id).orElseThrow();
}

// RIGHT: Mark read-only transactions
@Transactional(readOnly = true)  // Routes to replica
public User findById(Long id) {
    return userRepository.findById(id).orElseThrow();
}
```

### Common Mistake 2: Wrong Connection Pool Sizing

```yaml
# WRONG: Pool too small for load
hikari:
  maximum-pool-size: 5  # Only 5 connections!
  
# With 100 concurrent requests:
# 95 requests wait in queue
# Massive latency

# WRONG: Pool too large
hikari:
  maximum-pool-size: 500  # Way too many!
  
# Problems:
# - Database can't handle 500 connections
# - Memory wasted on idle connections
# - Connection overhead

# RIGHT: Size based on workload
# Formula: connections = (core_count * 2) + effective_spindle_count
# For web apps: Start with 10-20, monitor and adjust
hikari:
  maximum-pool-size: 20
  minimum-idle: 5
```

### Common Mistake 3: Ignoring Replication Lag

```java
// WRONG: Assume replica is always up-to-date
@Transactional
public void updateAndNotify(Long userId, String newName) {
    userRepository.updateName(userId, newName);  // Goes to primary
}

@Transactional(readOnly = true)
public void sendWelcomeEmail(Long userId) {
    User user = userRepository.findById(userId);  // Goes to replica
    // Might get old name if replication lag!
    emailService.send(user.getEmail(), "Welcome " + user.getName());
}

// RIGHT: Read from primary after write
@Transactional
public void updateAndNotify(Long userId, String newName) {
    userRepository.updateName(userId, newName);
    User user = userRepository.findById(userId);  // Same transaction, primary
    emailService.send(user.getEmail(), "Welcome " + user.getName());
}
```

### Common Mistake 4: Connection Leaks

```java
// WRONG: Connection not returned to pool
public void processData() {
    Connection conn = dataSource.getConnection();
    try {
        // Do work...
        if (someCondition) {
            return;  // Connection leaked!
        }
        // More work...
    } finally {
        // conn.close() never called on early return!
    }
}

// RIGHT: Use try-with-resources
public void processData() {
    try (Connection conn = dataSource.getConnection()) {
        // Do work...
        if (someCondition) {
            return;  // Connection automatically closed
        }
        // More work...
    }  // Connection returned to pool here
}

// BEST: Use Spring's JdbcTemplate or JPA
@Transactional
public void processData() {
    // Spring manages connections automatically
    repository.doWork();
}
```

### Performance Gotchas

**1. Too Many Replicas**

```
Scenario: 10 replicas for a database with few writes

Problem:
- Primary must send WAL to 10 replicas
- Network bandwidth consumed
- Primary CPU for replication

Solution:
- Use cascading replication
- Primary â†’ 2 replicas â†’ 4 replicas each
- Reduces primary load
```

**2. Replica Lag During Bulk Operations**

```
Scenario: Nightly batch job inserts 1M rows

Problem:
- Massive WAL generated
- Replicas fall behind
- Morning users see stale data

Solution:
- Throttle batch operations
- Run during low-traffic periods
- Consider separate replica for batch reads
```

---

## 8ï¸âƒ£ When NOT to Use This

### When NOT to Use Read Replicas

1. **Write-heavy workloads**
   - Replicas don't help with writes
   - Consider sharding instead

2. **Strong consistency requirements**
   - Replicas always have some lag
   - Use synchronous replication or single node

3. **Small databases**
   - Single node handles the load
   - Added complexity not worth it

4. **Complex transactions reading own writes**
   - Would need to route everything to primary anyway

### When NOT to Use Connection Pooling

1. **Serverless/Lambda functions**
   - Short-lived, pools don't persist
   - Use external poolers (RDS Proxy, PgBouncer)

2. **Single-query scripts**
   - Pool overhead not worth it
   - Direct connection is fine

### Signs Your Read Scaling Strategy is Wrong

- Replicas constantly lagging behind
- Connection pool always exhausted
- Primary still overloaded despite replicas
- Users complaining about stale data
- Complex routing logic causing bugs

---

## 9ï¸âƒ£ Comparison with Alternatives

### Read Scaling Approaches

| Approach | Complexity | Staleness | Use Case |
|----------|------------|-----------|----------|
| Read Replicas | Medium | Seconds | General read scaling |
| Caching (Redis) | Low | Configurable | Hot data |
| CDN | Low | Minutes | Static content |
| Sharding | High | None | Write scaling too |
| CQRS | High | Seconds-minutes | Complex domains |

### Connection Pooling Solutions

| Solution | Type | Best For |
|----------|------|----------|
| HikariCP | Application | Java applications |
| PgBouncer | External | PostgreSQL, serverless |
| ProxySQL | External | MySQL, read/write split |
| RDS Proxy | Managed | AWS serverless |

### When to Use What

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              READ SCALING DECISION TREE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  Is data frequently accessed and rarely changes?            â”‚
â”‚  â””â”€â”€ YES â†’ Use caching (Redis, Memcached)                   â”‚
â”‚  â””â”€â”€ NO â†’ Continue                                          â”‚
â”‚                                                              â”‚
â”‚  Can you tolerate seconds of staleness?                     â”‚
â”‚  â””â”€â”€ YES â†’ Use read replicas                                â”‚
â”‚  â””â”€â”€ NO â†’ Continue                                          â”‚
â”‚                                                              â”‚
â”‚  Is it static content (images, CSS, JS)?                    â”‚
â”‚  â””â”€â”€ YES â†’ Use CDN                                          â”‚
â”‚  â””â”€â”€ NO â†’ Continue                                          â”‚
â”‚                                                              â”‚
â”‚  Need to scale writes too?                                  â”‚
â”‚  â””â”€â”€ YES â†’ Consider sharding                                â”‚
â”‚  â””â”€â”€ NO â†’ Single node might be enough                       â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Ÿ Interview Follow-Up Questions WITH Answers

### L4 (Entry-Level) Questions

**Q1: What is a read replica and why do we use it?**

**Answer:**
A read replica is a copy of the primary database that receives updates through replication. We use read replicas to:

1. **Scale read capacity**: If one database handles 20K queries/second and you need 100K, you can add 4 replicas to handle the extra load.

2. **Reduce primary load**: Move read traffic off the primary so it can focus on writes.

3. **Geographic distribution**: Place replicas closer to users for lower latency.

4. **Reporting/analytics**: Run heavy queries on replicas without affecting production.

The trade-off is that replicas may have slightly stale data due to replication lag. Writes still must go to the primary.

**Q2: What is connection pooling and why is it important?**

**Answer:**
Connection pooling maintains a set of reusable database connections instead of creating new ones for each request.

It's important because:
1. **Creating connections is expensive**: TCP handshake, authentication, and session setup takes 50-100ms.
2. **Database connection limits**: Databases have max connection limits. Without pooling, you'd exhaust them quickly.
3. **Performance**: Reusing connections means queries start immediately instead of waiting for connection setup.

A typical configuration:
- Minimum connections: 5 (always ready)
- Maximum connections: 20 (cap to prevent overload)
- Idle timeout: 10 minutes (close unused connections)

### L5 (Mid-Level) Questions

**Q3: How would you handle the read-after-write consistency problem?**

**Answer:**
The problem: User writes data, then immediately reads it, but the read goes to a replica that hasn't received the write yet.

Solutions:

1. **Read from primary after write**: For N seconds after a write, route that user's reads to primary. Simple but increases primary load.

2. **Version tracking**: 
   - After write, return version number to client
   - Client includes version in subsequent reads
   - If replica version < client version, route to primary

3. **Sticky sessions**: Route user to same replica that's closest to primary in replication chain.

4. **Synchronous replication**: Wait for replica to confirm before acknowledging write. Eliminates lag but slows writes.

I'd choose based on requirements:
- High traffic, some staleness OK â†’ Version tracking
- Critical data, can't be stale â†’ Synchronous replication
- Simple implementation needed â†’ Read from primary after write

**Q4: How would you size a connection pool?**

**Answer:**
Connection pool sizing depends on several factors:

**Formula starting point:**
```
connections = (CPU cores * 2) + effective_spindle_count
```
For SSDs, spindle count â‰ˆ 1. For a 4-core machine: 4*2 + 1 = 9 connections.

**Practical considerations:**

1. **Measure actual usage**: Monitor active vs idle connections under load.

2. **Consider query duration**: 
   - Fast queries (1ms): Fewer connections needed
   - Slow queries (100ms): More connections to maintain throughput

3. **Database limits**: PostgreSQL default max_connections = 100. Your pools across all app servers must stay under this.

4. **Avoid too large**: 
   - Memory wasted on idle connections
   - Database overhead managing connections
   - Context switching overhead

**My approach:**
- Start with 10-20 connections per application instance
- Monitor pool utilization and wait times
- Increase if threads frequently wait for connections
- Decrease if many connections are idle

### L6 (Senior) Questions

**Q5: Design a read scaling strategy for a global application with millions of users.**

**Answer:**
I'd use a multi-tier approach:

**Tier 1: CDN + Edge Caching**
- Static content (images, CSS, JS) at edge
- API responses for public data (product listings)
- Reduces origin load significantly

**Tier 2: Application Caching (Redis)**
- Hot data: User sessions, frequently accessed records
- TTL based on data freshness requirements
- Cache-aside pattern with write-through for critical data

**Tier 3: Read Replicas per Region**
```
US-East:
  Primary (writes)
  2 Read Replicas
  
US-West:
  2 Read Replicas (async from US-East primary)
  
EU-West:
  2 Read Replicas (async from US-East primary)
  
APAC:
  2 Read Replicas (async from US-East primary)
```

**Tier 4: Database Sharding (if needed)**
- Shard by user_id for user-specific data
- Global tables for shared data

**Consistency handling:**
- Read-your-writes via version tracking in Redis
- Critical operations (payments) always hit primary
- Accept eventual consistency for feeds, recommendations

**Monitoring:**
- Replication lag per replica
- Cache hit rates
- Connection pool utilization
- Query latency percentiles

**Q6: How would you handle a scenario where replication lag is causing production issues?**

**Answer:**
Immediate response:

1. **Assess severity:**
   - How much lag? Seconds vs minutes
   - What's affected? All users or specific features
   - Is it growing or stable?

2. **Quick mitigations:**
   - Route more traffic to primary (if it can handle it)
   - Increase lag threshold for non-critical reads
   - Disable features that require fresh data

3. **Identify root cause:**
   - Check replica resources (CPU, disk I/O, memory)
   - Check network between primary and replica
   - Check for long-running queries on replica
   - Check for large transactions on primary

**Common causes and fixes:**

**Cause: Replica under-resourced**
- Fix: Scale up replica (more CPU, faster disk)

**Cause: Large batch job on primary**
- Fix: Throttle batch operations, run during off-peak

**Cause: Long-running queries on replica**
- Fix: Kill queries, add query timeout, move to dedicated replica

**Cause: Network issues**
- Fix: Check network, consider replica in same AZ

**Prevention:**
- Alert on lag > threshold (e.g., 10 seconds)
- Monitor replica resource utilization
- Separate replicas for OLTP vs analytics
- Regular load testing to find limits

---

## 1ï¸âƒ£1ï¸âƒ£ One Clean Mental Summary

Read replicas scale read capacity by distributing queries across multiple database copies. The primary handles all writes and replicates changes to replicas. This works because most applications are read-heavy (90%+ reads). The trade-off is replication lag, meaning replicas may have slightly stale data.

Connection pooling reuses database connections instead of creating new ones for each request. Creating connections is expensive (50-100ms), so pooling dramatically improves performance. Size pools based on workload: too small causes queuing, too large wastes resources.

The read-after-write problem occurs when a user writes data then reads from a stale replica. Solutions include reading from primary after writes, version tracking, or sticky sessions. Choose based on your consistency requirements and traffic patterns.

Key practices: Mark read-only transactions explicitly for routing, monitor replication lag and alert on thresholds, size connection pools based on actual usage, and implement read-your-writes for user-facing features. Don't over-engineer: start simple, measure, then optimize.

